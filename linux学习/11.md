

# 正则表达式

## 基础正则表达式

利用[ ]来搜寻字符集

[ae]

grep -n 't[ae]st' r*   //[ae] 代表一个字符占位，即该字符可以为a或者e

 grep -n '[^[^g]]oo' r*   //  反向选择 ，即 不以该字符不为g的字符

[a-z] 如果字符是连续的，就可以写成这样 中间加 -。

linux中还有 【：lower：】代表【a-z】 、【：digit：】代表【1-9】、【：upper：】代表【A-Z】

**行首 行尾字符^  $**

```
只在行首出现the
grep -n ’^the‘ regular-express.txt
开头都是小写字母
grep -n '^[a-z]' regular-express.txt
也可如下所示
grep -n '^[[:lower：]]' regular-express.txt
不想以英文字符开头
grep -n '^[^[a-zA-Z]]' regular-express.txt // ^在[]代表反向选择，在外边代表一行开头的意思
行尾以小数点结束
grep -n '\.$' regular-express.txt // .需要转义， $表示一行结尾的意思


```

**正则表达式中**

- ​	**点  . 代表一定有任意一个字符**
- 星号（*）**代表 重复前一个字符 ，0 到无穷多次**

```
找出g??d的字符
grep -n 'g..d' regular_express.txt
找出 oo, ooo, oooo的数据
至少含有一个o
grep -n 'oo*' r*
至少含有两个o
grep -n 'ooo*' r*
找出g开头和g结尾的字符串，当中的字符可有可无
grep -n 'g.*g' r*         // .* 代表零个或多个任意字符


```

**限定连续正则表达式字符范围 {}**

```
如果想限制一个范围区间内的重复字符？ 比如找出两个到五个o的连续字符串 ，要用到限定范围的字符{}。因为{和}的符号在shell是有特殊意义的，需要转义符\
grep -n 'o\{2\}' regular_express.txt
g后面有2-5个o，然后再接一个g的字符串
grep -n 'go\{2，5\}g' regular_express.txt
想要2个o以上的gooo...g,
grep -n 'go\{2,\}g' regular_express.txt

```

基础正则表达式整理

| RE字符    |                                                              |
| :-------- | ------------------------------------------------------------ |
| ^word     | 寻找的字符串在行首                                           |
| word$     | 寻找的字符串在行尾                                           |
| .         | 代表一定有一个任意字符的字符                                 |
| \         | 转义符，将特殊符号的特殊意义去掉                             |
| *         | 重复零个到多个的前一个RE字符                                 |
| 【list】  | 字符集合的RE字符，里边列出想查找的字符。在【】当中仅代表一个待查找的字符 |
| 【n1-n2】 | [a-z]  [A-Z]  [0-9]                                          |
| [^list]   | 字符集合的RE字符，里面列出不要的字符串或范围，方向选择的意思 |
| \\{n ,m}\ | 连续n到m个的前一个RE字符， 若为\\{n \\},，则是连续n个前一个RE字符；若为\\{n， \\},，则是连续n个以上的前一个RE字符； |

## sed工具

```
 //sed 删除2-5 行
 nl /etc/passwd | sed '2,5d'  // d 代表删除
 // sed后面如果要接多个动作，每个动作前要加 -e 才行
cat passwd.old | sed -e '4d' -e '6c "no six line"' > passwd.new

```

## 扩展正则表达式

普通正则表达式 去除空白和行首为#的列

```
普通正则表达式 去除空白和行首为#的列，需要搜寻两次
grep -v '^$' regular_express.txt | grep -v '^#'
扩展正则表达式,通过| 只需一次搜寻。扩展正则表达式使用 egrep 或 grep -E
egrep -v '^$|^#' regular_express.txt 

+ 重复一个或多个前一个RE字符    egrep -n 'go+d' regular_express.txt
? 零个或一个的前一个RE字符     egrep -n 'go?d' regular_express.txt  
//go+d 与 go?d 与go*d相同

| 用或的方式找出数个字符串  找出 gd 或good这两个字符串   egrep -n 'gd|good' regular_express.txt

() 找出群组 字符串   例如寻找 glad 或good 这两个字符串，因为g和d是重复的，所以将la 与oo列于()当中，并以|隔开。   egrep -n 'g(la|oo)d' regular_express.txt

()+ 多个重复群组的判断   例如 将AxyzxyzxyzxyzC用echo打出，在使用如下搜寻：
	 echo 'AxyzxyzxyzxyzC' | egrep 'A(xyz)+C'
	 目的是寻找A开头，C结尾，中间是一个或多个'xyz'字符串的意思
! 在正则表达式当中不是特殊字符
```

## 格式化打印  printf

```
printf '%s\t %s\t %s\t %s\t %s\t  \n' $(cat printf.txt)
输出入下
Name     Chinese         English         Math    Average
DmTsai   80      60      92      77.33
VBird    75      55      80      70.00
Ken      60      90      70      73.33

格式化
printf '%10s\t %5i\t %5i\t %5i\t %8.2f\t  \n' $(cat printf.txt | grep -v Name )  

	DmTsai          80      60      92      77.33
     VBird          75      55      80      70.00
       Ken          60      90      70      73.33


16进位的45 对应的ascii字符
printf ‘\45\n’
输出   E



```

## awk 好用的数据处理工具

**awk主要是处理每一行的字段内的数据，而默认的字段分割符为空格键或 tab键。**

```
last -n 5

lhl      pts/0        192.168.0.153    Wed Nov  6 15:16   still logged in
reboot   system boot  3.10.0-862.el7.x Wed Nov  6 14:59 - 18:07  (03:08)
lhl      pts/0        192.168.0.153    Wed Nov  6 08:49 - 14:47  (05:57)
reboot   system boot  3.10.0-862.el7.x Wed Nov  6 08:37 - 14:47  (06:10)
lhl      pts/0        192.168.0.153    Tue Nov  5 09:12 - 17:34  (08:21)

wtmp begins Tue Apr 16 11:54:43 2019

$ last -n 5 | awk '{print $1 "\t" $3}'  //取出每一行的第一列和第三列，awk在处理数据时会默认数据是以tab或空格键进行分割  $1代表第一列，$3代表第三列，依次类推，而$0代表一整行的所有列。

lhl     192.168.0.153
reboot  boot
lhl     192.168.0.153
reboot  boot
lhl     192.168.0.153

wtmp    Tue
awk是以行为一次处理的单位，而以字段为最小的处理单位，数据有几行，有几列，通过awk的内建变量来获取
NF       每一行 $0拥有的字段总数
NR  	目前awk所处的是第几行数据
FS		目前的分割字符，默认空格键

列出每一行的账号 ，列出目前处理的行数，并列出改行有多少个字段
$ last -n 5 | awk '{print $1"\t lines " NR"\t columns" NF} '

awk 逻辑运算字符
>   大于
<
>=
<=
==
!=

在/etc/passwd 中以冒号： 作为字段分割，第一字段为账号，第三字段为uuid，查找第三栏小于10以下的数据，且仅列出账号和第三栏
cat /etc/passwd | awk '{FS=":"} $3 < 10   {print $1 "\t"  $3}'
//读入第一行的时候，变量$1, $2默认还是一空格建为分割的。可以通过BEGIN关键词预先设定，
如下所示
cat /etc/passwd | awk 'BEGIN {FS=":"} $3 < 10   {print $1 "\t"  $3}'


Name  1st   2nd   3th
VBIrd 23000 24000 25000
DMTSai 21000 20000 23000
Bird2 43000 42000 41000

如上表，计算个人总额： 第一行为说明，不加总，第二行以后进行合计运算

$ cat pay.txt | awk 'NR=1{printf "%10s %10s %10s %10s %10s \n",$1,$2,$3,$4,"Total"}
NR>=2{total=$2+$3+$4 printf "%10s %10d %10d %10d %10.2f \n",$1,$2,$3,$4,total}'




```

## 文件比对工具

### diff

```
//按行进行比对
diff  /etc/passwd.old  /etc/passwd.new

```

### cmp

```
cmp  /etc/passwd.old  /etc/passwd.new
```

patch

```
制作patch升级文件
diff -Naur passwd.old passwd.new > passwd.patch
 cat passwd.patch
 输出
 --- passwd.old  2019-11-07 09:55:43.369584238 +0800
+++ passwd.new  2019-11-07 10:12:06.849312573 +0800
@@ -1,9 +1,8 @@
 root:x:0:0:root:/root:/bin/bash
 bin:x:1:1:bin:/bin:/sbin/nologin
 daemon:x:2:2:daemon:/sbin:/sbin/nologin
-adm:x:3:4:adm:/var/adm:/sbin/nologin
 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
-sync:x:5:0:sync:/sbin:/bin/sync
+"no six line"
 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
 halt:x:7:0:halt:/sbin:/sbin/halt
 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
//更新旧版程序
patch -p0 < passwd.patch
//恢复旧版
patch -R  -p0 < passwd.patch



```

